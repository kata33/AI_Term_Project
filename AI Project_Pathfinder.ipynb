{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*****************************************************************************************************************************\n",
    "#Project   : Path Finder                                                                                                     #\n",
    "#Author    : Kata Revanth                                                                                                    #\n",
    "#            Sri ram Alluri                                                                                                  #\n",
    "#            Lavanya Chadwalada                                                                                              #\n",
    "#Objective : The Main Objective of the project is to demonstrate the Q-Learning Model in finding the optimal path to reach   #\n",
    "#the Goal State from any particular state in the Environment                                                                 #\n",
    "#Approach  : 1)Design the path Grid(for Visualization)                                                                       #\n",
    "#            2)Build Reward Matrix                                                                                           #\n",
    "#            3)Build Q-Learning Model using Bellmen Equation                                                                 #\n",
    "#            4)Build Q-Learning Model using Heuristic Fuction                                                                #\n",
    "#            5)Compare the Perfomance of Both models                                                                         #\n",
    "#            6)Evaluate the Metrics of the Q-Lerning Models                                                                  #\n",
    "#*****************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid environment where the agent is to be trained \n",
    "- There were 10 states and 1 Goal state in the grid for the agent to learn "
   ]
  },
  {
   "attachments": {
    "Path%20Finder.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Path%20Finder.png](attachment:Path%20Finder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the reward matrix for each state and action in the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4    5   6   7   8   9   10\n",
       "0   -1  -1  -1  -1   0   -1  -1  -1  -1  -1  -1\n",
       "1   -1  -1  -1   0  -1  100  -1  -1  -1  -1  -1\n",
       "2   -1  -1  -1   0  -1   -1   0  -1  -1  -1  -1\n",
       "3   -1   0   0  -1   0   -1  -1  -1  -1   0  -1\n",
       "4    0  -1  -1   0  -1   -1  -1  -1   0  -1  -1\n",
       "5   -1   0  -1  -1  -1   -1  -1   0  -1  -1  -1\n",
       "6   -1  -1   0  -1  -1   -1  -1   0  -1  -1  -1\n",
       "7   -1  -1  -1  -1  -1    0   0  -1  -1  -1  -1\n",
       "8   -1  -1  -1  -1   0   -1  -1  -1  -1   0  -1\n",
       "9   -1  -1  -1   0  -1   -1  -1  -1   0  -1   0\n",
       "10  -1  -1  -1  -1  -1   -1  -1  -1  -1   0  -1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = np.array([[-1,-1,-1,-1,0,-1,-1,-1,-1,-1,-1],\n",
    "                   [-1,-1,-1,0,-1,100,-1,-1,-1,-1,-1],\n",
    "                    [-1,-1,-1,0,-1,-1,0,-1,-1,-1,-1],\n",
    "                    [-1,0,0,-1,0,-1,-1,-1,-1,0,-1],\n",
    "                    [0,-1,-1,0,-1,-1,-1,-1,0,-1,-1],\n",
    "                    [-1,0,-1,-1,-1,-1,-1,0,-1,-1,-1],\n",
    "                    [-1,-1,0,-1,-1,-1,-1,0,-1,-1,-1],\n",
    "                    [-1,-1,-1,-1,-1,0,0,-1,-1,-1,-1],\n",
    "                    [-1,-1,-1,-1,0,-1,-1,-1,-1,0,-1],\n",
    "                    [-1,-1,-1,0,-1,-1,-1,-1,0,-1,0],\n",
    "                    [-1,-1,-1,-1,-1,-1,-1,-1,-1,0,-1]])\n",
    "\n",
    "pd.DataFrame(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the q-matrix with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_q(m,n):\n",
    "    return np.zeros((m,n))\n",
    "\n",
    "q_matrix = initialize_q(11,11)\n",
    "pd.DataFrame(q_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(q_matrix):\n",
    "    normalized_q = q_matrix/max(q_matrix[q_matrix.nonzero()]) * 100\n",
    "    return normalized_q.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_state(rooms = 11):\n",
    "    return np.random.randint(0,rooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Q-Learning Model Building to reach Goal State(i.e. 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(episode):\n",
    "    gamma=0.8\n",
    "    Time_step = 0\n",
    "    current_state = set_initial_state()\n",
    "\n",
    "    while True:\n",
    "        valid_actions = []\n",
    "        for action in enumerate(rewards[current_state]):\n",
    "            if action[1]!= -1:\n",
    "                valid_actions +=[action[0]]\n",
    "        action = random.choice(valid_actions)\n",
    "        cur_state_reward= rewards[current_state, action] \n",
    "        nxt_state_reward= max(q_matrix[action,])\n",
    "        q_current_state= cur_state_reward+(gamma*nxt_state_reward)\n",
    "        q_matrix[current_state, action]=q_current_state \n",
    "        new_state= action\n",
    "        print(q_matrix)\n",
    "        print(f\"Old State: {current_state} | New State: {new_state}\\n\\n\")\n",
    "        current_state = new_state\n",
    "        Time_step = Time_step +1\n",
    "\n",
    "        if new_state== 5:\n",
    "            print(f\"Agent has reached it's goal!\")\n",
    "            print(f\"The Total Timesteps took by Agent for this episode {episode} is\",Time_step)\n",
    "            break\n",
    "    return Time_step,q_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full training for the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 500\n",
    "Total_steps = 0\n",
    "Learning_step_bi = []\n",
    "rewards_curve_bi = []\n",
    "for episode in range(1,iterations):\n",
    "    steps,q_matrix = train_agent(episode) \n",
    "    rewards_curve_bi.append(np.sum(q_matrix))\n",
    "    Learning_step_bi.append(Total_steps + steps)\n",
    "    Total_steps = Total_steps + steps\n",
    "print(\"Total Steps for full learning Process:\",Total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised q-matrix after an agent is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The final updated Q-Table after Training:\\n',pd.DataFrame(normalize_matrix(q_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges of the Simple Q-Learning Model\n",
    "- Required more Timesteps for reaching goal in each episode\n",
    "- Required more episodes\n",
    "- Needed more computation power as the environment size increases\n",
    "- Required more time for Agent to learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimised Q-Learning Model Implementation to reach Goal State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a larger grid \n",
    "- The number of transistions an agent makes in a single episode is too high which increases the space and time complexity.\n",
    "- Therefore, to have optimized results, a heuristic function is required which would Approximate the q-learning algorithm.\n",
    "- Below is the one of a kind heuristic function used for Improving Q-Learning Model\n",
    "    - Eachtime the valid actions for the current state are stored, those are compared with the already visited action for the by the agent, if valid action is already visited, then it is removed for the valid action and agent will not visit it for the epsiode.\n",
    "    - This will drastically reduce the total number of transistions that agent makes through its training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_q(m,n):\n",
    "    return np.zeros((m,n))\n",
    "\n",
    "q_matrix = initialize_q(11,11)\n",
    "pd.DataFrame(q_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(episode):\n",
    "    gamma=0.8\n",
    "    Time_step = 0\n",
    "    current_state = set_initial_state()\n",
    "    \n",
    "    visited_actions = []\n",
    "    while True:\n",
    "        valid_actions = []\n",
    "        temp_value = 0\n",
    "        for action in enumerate(rewards[current_state]):\n",
    "            if action[1]!= -1:\n",
    "                temp_value = action[0]\n",
    "                valid_actions +=[action[0]]\n",
    "                if action[0] in visited_actions:\n",
    "                    index = valid_actions.index(action[0])\n",
    "                    valid_actions.pop(index)\n",
    "        if len(valid_actions) == 0:\n",
    "            break\n",
    "        action = random.choice(valid_actions)\n",
    "        visited_actions.append(action)\n",
    "        cur_state_reward= rewards[current_state, action] \n",
    "        nxt_state_reward= max(q_matrix[action,])\n",
    "        q_current_state= cur_state_reward+(gamma*nxt_state_reward)\n",
    "        q_matrix[current_state, action]=q_current_state \n",
    "        new_state= action\n",
    "        print(q_matrix)\n",
    "        print(f\"Old State: {current_state} | New State: {new_state}\\n\\n\")\n",
    "        current_state = new_state\n",
    "        Time_step = Time_step +1\n",
    "\n",
    "        if new_state== 5:\n",
    "            print(f\"Agent has reached it's goal!\")\n",
    "            print(f\"The Total Timesteps took by Agent for this episode {episode} is\",Time_step)\n",
    "            break\n",
    "    return Time_step,q_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Training for the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 500\n",
    "Total_steps = 0\n",
    "Learning_step_ai = []\n",
    "rewards_curve_ai = []\n",
    "for episode in range(1,iterations):\n",
    "    steps,q_matrix = train_agent(episode)\n",
    "    rewards_curve_ai.append(np.sum(q_matrix))\n",
    "    Learning_step_ai.append(Total_steps + steps)\n",
    "    Total_steps = Total_steps + steps\n",
    "    \n",
    "print(\"Total Steps for full learning Process:\",Total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalised q-matrix after an agent is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The final updated Q-Table after Training:\\n',pd.DataFrame(normalize_matrix(q_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test metrics for the q-learning agent performance when heuristic is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(0,15000)\n",
    "plt.plot(range(1,500),Learning_step_bi, label = 'Without Heuristic')\n",
    "plt.plot(range(1,500),Learning_step_ai, label = 'Using Heuristic')\n",
    "plt.title('Q-Learning Model Learning Process')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Total Cummulative Steps')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising total rewards for an agent \n",
    "## simple Q-learning algorithm Vs Q-learning algorithm with a heuristic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(0,4000)\n",
    "plt.plot(range(1,500),rewards_curve_bi)\n",
    "plt.title('Q-Learning Rewards Learning Process - Without Heuristic')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Total Cummulative Rewards')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(0,4000)\n",
    "plt.plot(range(1,500),rewards_curve_ai)\n",
    "plt.title('Q-Learning Rewards Learning Process - With Heuristic')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Total Cummulative Rewards')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_agent(init_state,q_table):\n",
    "    print(\"start state:\", init_state)\n",
    "    state = init_state\n",
    "    steps = 0\n",
    "    while True:\n",
    "        steps = steps + 1\n",
    "        action = np.argmax(q_table[state,:])\n",
    "        print(action)\n",
    "        state = action\n",
    "        if action == 5:\n",
    "            print('Goal Reached!')\n",
    "            return steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_state = 8\n",
    "steps = deploy_agent(Start_state,q_matrix)\n",
    "print(\"Number of Steps took by Agent to reach Goal:\",steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Q-Learning Model\n",
    "- Updated Q-Table \n",
    "    - Initally Q table is Initialied with zeroes, once the training is completed, Q-Table is updated with the Maximum rewards for the each state, action pair which helps the agent to choose the best action in that particular state\n",
    "- Rewards Learning\n",
    "    - For each episode , reward is calculated and updated Q-Table and the reward learning progress graph is shown above.\n",
    "- Total Number of Timesteps for the complete Training process\n",
    "    - Upon using the Heuristic fuction, the search process computing process is improved and Q-Table is updated with the Maximum rewards with the least number of Timesteps for episode.\n",
    "- Total Regrets\n",
    "    - Even upon the successful training, there will always be the chance of regrets for the agent not to choose the optimal path towards the goal. In our Q-learning model even after success training, we can see 1 regret for the state 6 in which agent miss to choose the optimal path and rather used more steps to reach the goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- Q-Learning Model using Heuristic function outperfom the Simple Q-Learning Model intems of performance. \n",
    "- We can see the huge reduction of total number of time steps for Q-Learning Model using Heuristic Function.\n",
    "- Agent learns quickly in Q-Learning Model using Heuristic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
